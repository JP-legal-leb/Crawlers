{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1L4i4_xCQsDIEps8hwHgGi834NBwNYS3N","authorship_tag":"ABX9TyMn/EbS6cN/vRImaqBIQPML"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!apt-get update -y > /dev/null\n","!apt-get install -y wget unzip > /dev/null\n","\n","# Install Google Chrome\n","!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb > /dev/null\n","!dpkg -i google-chrome-stable_current_amd64.deb > /dev/null 2>&1\n","!apt-get -f install -y > /dev/null\n","\n","# Get installed Chrome major version\n","!CHROME_VERSION=$(google-chrome --version | awk '{print $3}' | cut -d '.' -f 1) && \\\n","  echo \"Installed Chrome version: $CHROME_VERSION\" && \\\n","  wget -O /tmp/chromedriver.zip \"https://chromedriver.storage.googleapis.com/$CHROME_VERSION.0.5481.77/chromedriver_linux64.zip\" && \\\n","  unzip -o /tmp/chromedriver.zip -d /usr/local/bin/ && \\\n","  chmod +x /usr/local/bin/chromedriver\n"],"metadata":{"id":"7gU7Od-jU9xN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750862961685,"user_tz":-180,"elapsed":35109,"user":{"displayName":"Mohammed Lababidi","userId":"14108617793603566916"}},"outputId":"fe4e5e14-2feb-4a89-e5e1-ff0afee604c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","--2025-06-25 14:48:58--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n","Resolving dl.google.com (dl.google.com)... 142.250.101.190, 142.250.101.93, 142.250.101.136, ...\n","Connecting to dl.google.com (dl.google.com)|142.250.101.190|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 118033016 (113M) [application/x-debian-package]\n","Saving to: ‘google-chrome-stable_current_amd64.deb.1’\n","\n","google-chrome-stabl 100%[===================>] 112.56M  22.2MB/s    in 6.2s    \n","\n","2025-06-25 14:49:05 (18.2 MB/s) - ‘google-chrome-stable_current_amd64.deb.1’ saved [118033016/118033016]\n","\n","Installed Chrome version: 138\n","--2025-06-25 14:49:25--  https://chromedriver.storage.googleapis.com/138.0.5481.77/chromedriver_linux64.zip\n","Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.251.2.207, 142.250.141.207, 74.125.137.207, ...\n","Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.251.2.207|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2025-06-25 14:49:25 ERROR 404: Not Found.\n","\n"]}]},{"cell_type":"code","metadata":{"id":"86034107","executionInfo":{"status":"ok","timestamp":1750875512412,"user_tz":-180,"elapsed":2463,"user":{"displayName":"Mohammed Lababidi","userId":"14108617793603566916"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e87baeab-c02d-40fa-ad33-d7748d5d2755"},"source":["\n","import os\n","from bs4 import BeautifulSoup\n","from docx import Document\n","\n","input_folder = \"HTML_text\"\n","output_folder = \"Docx_output\"\n","\n","# Create output folder if not exists\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Loop through all .txt files in the input folder\n","for filename in os.listdir(input_folder):\n","    if filename.endswith(\".txt\"):\n","        input_path = os.path.join(input_folder, filename)\n","\n","        # Read the HTML content\n","        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n","            html = f.read()\n","\n","        # Use BeautifulSoup to strip tags\n","        soup = BeautifulSoup(html, \"html.parser\")\n","        plain_text = soup.get_text(separator=\"\\n\", strip=True)\n","\n","        # Create a Word document\n","        doc = Document()\n","        doc.add_paragraph(plain_text)\n","\n","        # Save as .docx with same name\n","        base_name = os.path.splitext(filename)[0]\n","        output_path = os.path.join(output_folder, f\"{base_name}.docx\")\n","        doc.save(output_path)\n","\n","        print(f\"✅ Converted: {filename} → {base_name}.docx\")\n","\n","print(\"\\n✅ All files converted and saved in 'Docx_output/' folder.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Converted: SocialInsurance.txt → SocialInsurance.docx\n","✅ Converted: النظام الموحد لمد الحماية التأمينية.txt → النظام الموحد لمد الحماية التأمينية.docx\n","✅ Converted: المستندات المطلوبة.txt → المستندات المطلوبة.docx\n","✅ Converted: نظام التقاعد العسكري.txt → نظام التقاعد العسكري.docx\n","✅ Converted: نظام التأمينات الاجتماعية 1445ه.txt → نظام التأمينات الاجتماعية 1445ه.docx\n","✅ Converted: نظام تبادل المنافع.txt → نظام تبادل المنافع.docx\n","✅ Converted: نظام التأمين ضد التعطل عن العمل - ساند.txt → نظام التأمين ضد التعطل عن العمل - ساند.docx\n","✅ Converted: المصطلحات.txt → المصطلحات.docx\n","✅ Converted: نظام التقاعد المدني .txt → نظام التقاعد المدني .docx\n","\n","✅ All files converted and saved in 'Docx_output/' folder.\n"]}]},{"cell_type":"code","source":["# Install required packages\n","!apt update > /dev/null\n","!apt install -y tesseract-ocr tesseract-ocr-ara poppler-utils > /dev/null\n","!pip install pytesseract python-docx pdf2image\n","\n","# Import libraries\n","import pytesseract\n","from pdf2image import convert_from_path\n","from docx import Document\n","import re\n","\n","# Convert PDF pages to images\n","pdf_path = '/content/Implementingregulationsfortheunemploymentsystem.pdf'  # Upload your file in Colab\n","images = convert_from_path(pdf_path)\n","\n","# Initialize Word document\n","doc = Document()\n","\n","# Process each page\n","for i, img in enumerate(images):\n","    text = pytesseract.image_to_string(img, lang='ara')\n","    # Remove invalid XML characters\n","    cleaned_text = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f]', '', text)\n","    doc.add_paragraph(cleaned_text)\n","    print(f\"✅ Processed page {i+1}\")\n","\n","# Save DOCX\n","output_path = \"/content/converted_output.docx\"\n","doc.save(output_path)\n","print(f\"✅ Saved: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dseNgh82rvx-","executionInfo":{"status":"ok","timestamp":1750882454763,"user_tz":-180,"elapsed":101926,"user":{"displayName":"Mohammed Lababidi","userId":"14108617793603566916"}},"outputId":"ccbb9d55-1163-4893-c737-65500fb0a5d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n","\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","\n","WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n","\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n","Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n","Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n","Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.0)\n","✅ Processed page 1\n","✅ Processed page 2\n","✅ Processed page 3\n","✅ Processed page 4\n","✅ Processed page 5\n","✅ Processed page 6\n","✅ Processed page 7\n","✅ Processed page 8\n","✅ Processed page 9\n","✅ Processed page 10\n","✅ Processed page 11\n","✅ Processed page 12\n","✅ Processed page 13\n","✅ Saved: /content/converted_output.docx\n"]}]},{"cell_type":"markdown","metadata":{"id":"e57a11ce"},"source":["I will use Playwright to extract the links, as it tends to be more stable in environments without a display server."]},{"cell_type":"code","source":[],"metadata":{"id":"Mb8puNk6INS3"},"execution_count":null,"outputs":[]}]}