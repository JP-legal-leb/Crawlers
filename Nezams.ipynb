{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"15sxJB8Icuqu46oiKm_LI0sh1LSBVhhBY","authorship_tag":"ABX9TyOZ1HMxlYF3f/GrLQn80+xT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bwDt4ya1LFEh"},"outputs":[],"source":["!pip install -q playwright nest_asyncio\n","!playwright install --with-deps chromium\n","!pip install playwright\n","!pip install pdf2docx\n"]},{"cell_type":"code","source":["import requests\n","import time\n","import json\n","\n","# Define the file name containing the law IDs\n","file_name = \"law IDs.txt\"\n","# Define the output file name for collected links\n","output_file_name = \"collected_links.txt\"\n","\n","url = \"https://nezams.com/wp-admin/admin-ajax.php\"\n","headers = {\n","    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://nezams.com/\",\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36\",\n","}\n","\n","try:\n","    with open(file_name, 'r') as f:\n","        law_ids = [line.strip() for line in f if line.strip()]\n","\n","    # Open the output file in append mode ('a'). Use 'w' to overwrite each time.\n","    with open(output_file_name, 'a', encoding='utf-8') as outfile:\n","        for law_id in law_ids:\n","            payload = f\"action=get_system_number&id={law_id}&sysn=1&pid={law_id}\"\n","\n","            try:\n","                r = requests.post(url, headers=headers, data=payload)\n","\n","                if r.status_code == 200:\n","                    try:\n","                        response_data = json.loads(r.text)\n","                        if response_data.get(\"success\") and \"data\" in response_data:\n","                            extracted_link = response_data[\"data\"]\n","                            outfile.write(extracted_link + '\\n') # Write link to file with a newline\n","                        else:\n","                            print(f\"No link found for ID {law_id}. Response indicates failure or missing 'data' field: {r.text[:200]}\")\n","                    except json.JSONDecodeError:\n","                        print(f\"Error: Could not decode JSON response for ID {law_id}. Response: {r.text[:200]}\")\n","                else:\n","                    print(f\"Request failed for ID {law_id} with status code {r.status_code}. Response: {r.text[:200]}\")\n","\n","            except requests.exceptions.RequestException as e:\n","                print(f\"Network error for ID {law_id}: {e}\")\n","\n","            time.sleep(0.1)\n","\n","    print(f\"\\nAll collected links have been saved to '{output_file_name}'.\")\n","\n","except FileNotFoundError:\n","    print(f\"Error: The file '{file_name}' was not found. Please upload 'law IDs.txt' to Colab.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hizi368ZufZq","executionInfo":{"status":"ok","timestamp":1750977100501,"user_tz":-180,"elapsed":1414760,"user":{"displayName":"Mohammed Lababidi","userId":"14108617793603566916"}},"outputId":"f5522045-9402-4edb-8c24-21473c7cb333"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","All collected links have been saved to 'collected_links.txt'.\n"]}]},{"cell_type":"code","source":["\n","import asyncio\n","import os\n","from playwright.async_api import async_playwright\n","from bs4 import BeautifulSoup\n","from docx import Document\n","from docx.shared import Pt\n","from docx.enum.text import WD_ALIGN_PARAGRAPH\n","from docx.oxml.ns import qn\n","\n","# Output folder\n","output_dir = \"/content/laws_docs\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Selectors to remove\n","unwanted_selectors = [\n","    \"div.fontsize.no-print\",\n","    \"span.share-icon\",\n","    \"span.total-readers\",\n","    \"div.subject-share\",\n","    \"span.numbe-s\",\n","    \"div#more-items\",\n","    \"ul#subject-nav-links\"\n","]\n","\n","# Save DOCX with RTL and right-aligned paragraphs\n","def save_docx(title, body, filename):\n","    doc = Document()\n","    section = doc.sections[0]\n","    section.right_to_left = True  # Full document RTL\n","\n","    style = doc.styles['Normal']\n","    style.font.name = 'Arial'\n","    style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Arial')\n","    style.font.size = Pt(14)\n","\n","    # Title (right-aligned)\n","    p_title = doc.add_paragraph()\n","    p_title.paragraph_format.right_to_left = True\n","    p_title.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n","    p_title.add_run(title)\n","\n","    # Body (right-aligned)\n","    p_body = doc.add_paragraph()\n","    p_body.paragraph_format.right_to_left = True\n","    p_body.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n","    p_body.add_run(body)\n","\n","    doc.save(filename)\n","\n","# Async scraper\n","async def scrape_and_save_all():\n","    with open(\"collected_links.txt\", \"r\", encoding=\"utf-8\") as f:\n","        urls = [line.strip() for line in f if line.strip()]\n","\n","    async with async_playwright() as p:\n","        browser = await p.chromium.launch(headless=True)\n","        context = await browser.new_context(locale=\"ar-SA\")\n","        page = await context.new_page()\n","\n","        for url in urls:\n","            try:\n","                await page.goto(url, timeout=20000)\n","                await page.wait_for_timeout(2000)\n","                html = await page.content()\n","                soup = BeautifulSoup(html, 'html.parser')\n","\n","                title_tag = soup.select_one(\"body > div.page > h1\")\n","                content_div = soup.select_one(\"body > div.page > div.post-page > div\")\n","                if not title_tag or not content_div:\n","                    continue\n","                title = title_tag.get_text(strip=True)\n","\n","                # Remove unwanted parts\n","                for selector in unwanted_selectors:\n","                    for tag in content_div.select(selector):\n","                        tag.decompose()\n","\n","                # Combine special spans into one line with spaces\n","                for outer in content_div.select('span.selectionShareable[style=\"color: #993300;\"]'):\n","                    inner_spans = outer.select('span.selectionShareable')\n","                    combined = ' '.join(s.get_text(strip=True) for s in inner_spans if s.get_text(strip=True))\n","                    outer.string = combined\n","                    for s in inner_spans:\n","                        s.decompose()\n","\n","                body_text = content_div.get_text(separator=\"\\n\", strip=True)\n","\n","                safe_title = title.replace(\"/\", \"-\").replace(\":\", \"،\").strip()\n","                filename = os.path.join(output_dir, f\"{safe_title}.docx\")\n","                save_docx(title, body_text, filename)\n","                print(f\"✅ Saved: {safe_title}\")\n","            except Exception as e:\n","                print(f\"❌ Failed: {url} — {str(e)}\")\n","\n","        await browser.close()\n","\n","# Run it\n","await scrape_and_save_all()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VekmACSYdwvr","executionInfo":{"status":"ok","timestamp":1750988576430,"user_tz":-180,"elapsed":34219,"user":{"displayName":"Mohammed Lababidi","userId":"14108617793603566916"}},"outputId":"5f7fb7d2-b7e8-4d9d-a0eb-8b49b44688c4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Saved: نظام صندوق الاستثمارات العامة\n","✅ Saved: نظام مكافحة التستر\n","✅ Saved: نظام القياس والمعايرة\n","✅ Saved: نظام السجل التجاري\n","✅ Saved: نظام صندوق التنمية العقارية\n","✅ Saved: نظام صندوق التنمية الزراعية\n","✅ Saved: نظام السياحة\n","✅ Saved: نظام الكهرباء\n","✅ Saved: تنظيم المركز السعودي لكفاءة الطاقة\n","✅ Saved: تنظيم إعانة البحث عن عمل\n"]}]}]}