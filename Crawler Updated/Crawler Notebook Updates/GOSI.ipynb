{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "7gU7Od-jU9xN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: playwright in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.52.0)\n",
            "Requirement already satisfied: python-docx in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.11)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.2)\n",
            "Requirement already satisfied: pyee<14,>=13 in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from playwright) (13.0.0)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from playwright) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyee<14,>=13->playwright) (4.14.1)\n",
            "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ali-d\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%playwright` not found.\n"
          ]
        }
      ],
      "source": [
        "#Dependencies\n",
        "%pip install playwright python-docx beautifulsoup4\n",
        "%playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1ofj2BJNPSm",
        "outputId": "46531f07-4361-4cc9-c2e3-cf58ad268d2a"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 123\u001b[0m\n\u001b[0;32m    120\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mrun(scrape_and_save_docx_rtl())\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[1], line 120\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m--> 120\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscrape_and_save_docx_rtl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\ali-d\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
            "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "import asyncio\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from docx import Document\n",
        "from docx.oxml.ns import qn\n",
        "from docx.oxml import OxmlElement\n",
        "from docx.shared import Pt\n",
        "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError\n",
        "\n",
        "OUTPUT_FOLDER = \"GOSI_DOCX\"\n",
        "MAIN_URL = \"https://www.gosi.gov.sa/ar/SystemsAndRegulations\"\n",
        "\n",
        "def ensure_out_dir():\n",
        "    Path(OUTPUT_FOLDER).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def make_rtl(paragraph):\n",
        "    \"\"\"Force paragraph RTL in python-docx.\"\"\"\n",
        "    p = paragraph._p\n",
        "    pPr = p.get_or_add_pPr()\n",
        "    bidi = OxmlElement(\"w:bidi\")\n",
        "    bidi.set(qn(\"w:val\"), \"true\")\n",
        "    pPr.append(bidi)\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    # Keep Arabic, letters, numbers, spaces, underscore, dash\n",
        "    # Strip anything else, truncate to safe length\n",
        "    safe = re.sub(r\"[^0-9A-Za-z\\u0600-\\u06FF _\\-]+\", \"\", name)\n",
        "    return safe.strip()[:180] or \"document\"\n",
        "\n",
        "async def scrape_and_save_docx_rtl():\n",
        "    ensure_out_dir()\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        # Headless Chromium is fine for servers/CI. Set headless=False to watch it run.\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto(MAIN_URL, timeout=60_000)\n",
        "        await page.wait_for_load_state(\"domcontentloaded\")\n",
        "\n",
        "        # The list of items to visit\n",
        "        await page.wait_for_selector(\"#mediaCenterElements li\", timeout=30_000)\n",
        "        items_all = await page.query_selector_all(\"#mediaCenterElements li\")\n",
        "\n",
        "        titles = []\n",
        "        for item in items_all:\n",
        "            text = (await item.inner_text()).strip()\n",
        "            if text and text != \"كتيبات الأنظمة\":\n",
        "                titles.append(text)\n",
        "\n",
        "        print(f\"✅ Total items to visit: {len(titles)}\\n\")\n",
        "\n",
        "        for idx, title in enumerate(titles, start=1):\n",
        "            print(f\"➡ Visiting ({idx}/{len(titles)}): {title}\")\n",
        "\n",
        "            # Reload the main page each loop to avoid stale handles\n",
        "            await page.goto(MAIN_URL, timeout=60_000)\n",
        "            await page.wait_for_selector(\"#mediaCenterElements li\", timeout=30_000)\n",
        "\n",
        "            # More reliable: use a locator that matches the LI with exact text\n",
        "            # (Playwright's has_text is substring; we filter exact match)\n",
        "            lis = page.locator(\"#mediaCenterElements li\")\n",
        "            count = await lis.count()\n",
        "            target_index = None\n",
        "            for i in range(count):\n",
        "                t = (await lis.nth(i).inner_text()).strip()\n",
        "                if t == title:\n",
        "                    target_index = i\n",
        "                    break\n",
        "\n",
        "            if target_index is None:\n",
        "                print(f\"⚠ Could not find item: {title}\")\n",
        "                continue\n",
        "\n",
        "            await lis.nth(target_index).click()\n",
        "\n",
        "            try:\n",
        "                await page.wait_for_selector(\"#systemsAndRegulationsPageContent\", timeout=30_000)\n",
        "                # Give the page a moment for dynamic content to finish rendering\n",
        "                await page.wait_for_load_state(\"networkidle\")\n",
        "            except PlaywrightTimeoutError:\n",
        "                print(f\"⚠ Timeout waiting for content: {title}\")\n",
        "                continue\n",
        "\n",
        "            content_div = await page.query_selector(\"#systemsAndRegulationsPageContent\")\n",
        "            if not content_div:\n",
        "                print(f\"⚠ No content container for: {title}\")\n",
        "                continue\n",
        "\n",
        "            html_content = await content_div.inner_html()\n",
        "\n",
        "            # Convert HTML to plain text (lxml parser is faster/better if installed)\n",
        "            soup = BeautifulSoup(html_content, \"lxml\")\n",
        "            plain_text = soup.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "            # Write DOCX (set Normal style a bit larger; force RTL on paragraph)\n",
        "            doc = Document()\n",
        "            try:\n",
        "                style = doc.styles[\"Normal\"]\n",
        "                font = style.font\n",
        "                font.size = Pt(12)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "            para = doc.add_paragraph(plain_text)\n",
        "            make_rtl(para)\n",
        "\n",
        "            safe_name = sanitize_filename(title)\n",
        "            output_path = os.path.join(OUTPUT_FOLDER, f\"{safe_name}.docx\")\n",
        "            doc.save(output_path)\n",
        "            print(f\"✅ Saved DOCX (RTL): {output_path}\\n\")\n",
        "\n",
        "        await browser.close()\n",
        "        print(f\"\\n✅ All pages processed. Files are in '{OUTPUT_FOLDER}/'.\\n\")\n",
        "\n",
        "def main():\n",
        "    asyncio.run(scrape_and_save_docx_rtl())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
